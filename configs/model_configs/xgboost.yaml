# Конфигурация для XGBoost модели

hyperparameters:
  objective: "binary:logistic"
  eval_metric: "auc"
  max_depth: 6
  learning_rate: 0.1
  n_estimators: 1000
  subsample: 0.8
  colsample_bytree: 0.8
  min_child_weight: 1
  gamma: 0
  reg_alpha: 0
  reg_lambda: 1
  random_state: 42
  n_jobs: -1

# Параметры для поиска гиперпараметров
hyperopt_space:
  learning_rate: [0.01, 0.3]
  max_depth: [3, 10]
  n_estimators: [100, 2000]
  subsample: [0.5, 1.0]
  colsample_bytree: [0.5, 1.0]
  min_child_weight: [1, 10]
  gamma: [0, 5]
  reg_alpha: [0, 10]
  reg_lambda: [0, 10]

# Специфичные настройки обучения
training:
  early_stopping_rounds: 100
  verbose: false